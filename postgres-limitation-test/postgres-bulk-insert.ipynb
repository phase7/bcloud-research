{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import credentials,psycopg2,time,tqdm\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "__username = credentials.user\n",
    "__password = credentials.passw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is forked from [KhanShaheb34/Explore-PostgreSQL](https://nbviewer.jupyter.org/github/KhanShaheb34/Explore-PostgreSQL/blob/master/Stress-test/StressTest.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of(fn, args=None, verbose=True):\n",
    "    start_time = time.time()\n",
    "    if(args):\n",
    "        out = fn(args)\n",
    "    else:\n",
    "        out = fn()\n",
    "    run_time = time.time() - start_time\n",
    "    if verbose:\n",
    "        print(\"Time: %ss\" % run_time)\n",
    "    return run_time, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = psycopg2.connect(database=\"testinsert1\", user=__username)\n",
    "cur = test1.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a table where I can insert data. This query is tested in the *insert testing* notebook in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table_schema = '''\n",
    "CREATE TABLE IF NOT EXISTS funtable_onerow( \n",
    "id BIGSERIAL PRIMARY KEY,\n",
    "username VARCHAR(50) NOT NULL,\n",
    "password VARCHAR(80) NOT NULL,\n",
    "email VARCHAR(200),\n",
    "phone BIGINT\n",
    ");\n",
    "'''\n",
    "try:\n",
    "    cur.execute(sql_table_schema)\n",
    "except InFailedSqlTransaction:\n",
    "    print('InFailedSqlTransaction error occured! Did any of your queries fail recently and you haven\\'t rolled back?')\n",
    "    print(\"Rolling back because of\", \"InFailedSqlTransaction\")\n",
    "    cur.execute(\"ROLLBACK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we insert a row using faker library or from a CSV file, that data retrieval from source takes a little amount of time to load into memory. So, for the *first step* we'll insert same data for a number of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('dean51', '@Ry9DzF)Zl', 'ronaldhorton@hotmail.com', '7398670308885')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onerow_data = f\"('{fake.simple_profile()['username']}', '{fake.password()}', '{fake.email()}', '{fake.msisdn()}')\"\n",
    "onerow_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename = \"funtable_onerow\"\n",
    "col_header = \"username, password, email, phone\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by making a function so that I can time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_row_insert():\n",
    "    p =  cur.execute(\n",
    "                f\"INSERT INTO {tablename} \"\n",
    "                f\"({col_header}) VALUES \" + onerow_data)\n",
    "def insert_5k():\n",
    "    for _ in tqdm.tqdm([0]*5000):\n",
    "        one_row_insert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out I can time the functions with `tqdm` library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:35<00:00, 52.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 95.2841067314148s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95.2841067314148, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_of(insert_5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I can start pushing more data now. **I'll in crease rows by 10 fold!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_50k():\n",
    "    for _ in tqdm.tqdm([0]*50000):\n",
    "        one_row_insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [17:03<00:00, 48.86it/s]  \n"
     ]
    }
   ],
   "source": [
    "insert_50k()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right! Let's keep it going! Let's see what happens if I start putting in unique data using `faker` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_unique_5k():\n",
    "    for _ in tqdm.tqdm([0]*5000):\n",
    "        cur.execute(\n",
    "            f\"INSERT INTO {tablename} \"\n",
    "            f\"({col_header}) VALUES \"\n",
    "            f\"('{fake.simple_profile()['username']}', '{fake.password()}', '{fake.email()}', '{fake.msisdn()}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:31<00:00, 54.85it/s]\n"
     ]
    }
   ],
   "source": [
    "insert_unique_5k()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What just happened?!\n",
    "Did faker take *less* time?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:38<00:00, 50.97it/s]\n"
     ]
    }
   ],
   "source": [
    "insert_unique_5k()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm looks llike it varies! Alright then, moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_unique_50k():\n",
    "    for _ in tqdm.tqdm([0]*50000):\n",
    "        cur.execute(\n",
    "            f\"INSERT INTO {tablename} \"\n",
    "            f\"({col_header}) VALUES \"\n",
    "            f\"('{fake.simple_profile()['username']}', '{fake.password()}', '{fake.email()}', '{fake.msisdn()}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50k inserts took one minute more - that was expected. But other timing was close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [18:02<00:00, 46.20it/s]  \n"
     ]
    }
   ],
   "source": [
    "insert_unique_50k()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next we'll need to insert from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "test1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.execute(\"ROLLBACK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found this article in favor of `\\copy` instead of `INSERT` [bulk insert - copy vs insert](https://www.citusdata.com/blog/2017/11/08/faster-bulk-loading-in-postgresql-with-copy/)\n",
    "\n",
    "will follow up on those later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
